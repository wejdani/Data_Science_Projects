{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bd9a70a",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"200\" height=\"200\" src=\"https://static.wikia.nocookie.net/lego/images/2/23/PPG_logo.png\"> \n",
    "\n",
    "# <span style=\"color:#EF7C8E\">Introduction 3 - Machine Learning 3 Assignment - Machine Learning </span>\n",
    " \n",
    "\n",
    "\n",
    "## <span style=\"color:#55BB99\"> By: Wejdan Al-Ahmadi</span>\n",
    "<hr style=\"border:2px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88789e4c",
   "metadata": {},
   "source": [
    "### <span style=\"color:#EF7C8E\">1. Build an Evaluation function: </span>\n",
    "\n",
    "Build a function that takes a vector of predictions using your heuristic and a vector of realizations (the correct values) from the data set and calculate:\n",
    "* Precision (Classification \"RAIN\" column)\n",
    "* Recall  (Classification \"RAIN\" column)\n",
    "* SSE Cost of your prediction (Regression \"PRCP\" column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e41b7780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here is an example of how to build and populate a hurestic model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import time\n",
    "import datetime\n",
    "from matplotlib.pyplot import figure\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, recall_score, precision_score\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aa589d",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#55BB99\"> 1) Data Import and Cleaning:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c87ef36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.5\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('./data/seattle_weather_1948-2017.csv')\n",
    "\n",
    "def RAIN_INSERTION(cols):\n",
    "    \"\"\"\n",
    "    Insert False where NaN values are present\n",
    "    \"\"\"\n",
    "    RAIN=cols[0]\n",
    "    if pd.isnull(RAIN):\n",
    "        return False\n",
    "    else:\n",
    "        return RAIN\n",
    "    \n",
    "def PRCP_INSERTION(col):\n",
    "    \"\"\"\n",
    "    Insert the Mean of PRCP where NaN values are present\n",
    "    \"\"\"\n",
    "    PRCP=col[0]\n",
    "    if pd.isnull(PRCP):\n",
    "        return df['PRCP'].mean()\n",
    "    else:\n",
    "        return PRCP\n",
    "    \n",
    "# Apply the functions\n",
    "df['RAIN']=df[['RAIN']].apply(RAIN_INSERTION,axis=1)\n",
    "df['PRCP']=df[['PRCP']].apply(PRCP_INSERTION,axis=1)\n",
    "\n",
    "# First quartile (Q1)\n",
    "Q1 = np.percentile(df['TMAX'], 25, interpolation = 'midpoint')\n",
    "  \n",
    "# Third quartile (Q3)\n",
    "Q3 = np.percentile(df['TMAX'], 75, interpolation = 'midpoint')\n",
    "  \n",
    "# Interquaritle range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# lower bound outliers --> Q1 - 1.5(IQR)\n",
    "# higher bound outliers --> Q3 + 1.5 (IQR)\n",
    "\n",
    "print(Q3+ 1.5*(IQR))\n",
    "\n",
    "#Dropping the outliers from TMIN column\n",
    "df=df.drop(df[df['TMIN']<17 ].index)\n",
    "#Dropping the outliers from TMAX columns i.e. the value more than 100\n",
    "df=df.drop(df[(df['TMAX']>97.5) | (df['TMAX']< 21.5)].index)\n",
    "#Dropping the outliers from PRCP columns i.e. the value more than 0.275\n",
    "df=df.drop(df[(df['PRCP']>0.25) | (df['PRCP']< -0.15) ].index)\n",
    "\n",
    "# Reset index and drop index column\n",
    "df = df.reset_index().drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff82f13",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#55BB99\"> 2) Hueristic and Confusion Matrix function for Rain and PRCP:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0edcb3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_pred_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43dfc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x --> Tomorrow\n",
    "# x-1 --> Today\n",
    "# x-2 --> Yesterday\n",
    "\n",
    "def heuristic_rain(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Simple heuristic:\n",
    "    \n",
    "    If it rained yesterday or the day before yesterday\n",
    "    \n",
    "    then predict rain else predict no rain\n",
    "    \n",
    "    Frist two rows are predicted false be default\n",
    "    \"\"\"\n",
    "    \n",
    "    preds = []\n",
    "    for x in range(len(df)):\n",
    "        if x <2:\n",
    "            preds.append(False)\n",
    "        else:\n",
    "            if (df.iloc[x-1][\"RAIN\"] == True):\n",
    "                if(df.iloc[x][\"TMAX\"]<=65) & (df.iloc[x][\"PRCP\"] >=0.01)&(df.iloc[x][\"TMIN\"]<=45):\n",
    "                    preds.append(True)\n",
    "                else: \n",
    "                    preds.append(False)  \n",
    "            elif (df.iloc[x-2][\"RAIN\"] == True):\n",
    "                if (df.iloc[x][\"TMAX\"]<=65) & (df.iloc[x][\"PRCP\"] >=0.01)&(df.iloc[x][\"TMIN\"]<=45):\n",
    "                    preds.append(True)\n",
    "                else:\n",
    "                    preds.append(False)\n",
    "            elif (df.iloc[x-3][\"RAIN\"] == True):\n",
    "                if (df.iloc[x][\"TMAX\"]<=65) & (df.iloc[x][\"PRCP\"] >=0.01)&(df.iloc[x][\"TMIN\"]<=45):\n",
    "                    preds.append(True)\n",
    "                else:\n",
    "                    preds.append(False)\n",
    "\n",
    "            else: \n",
    "                preds.append(False)\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b453b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_confuse_rain(true_c, pred_c):\n",
    "    \n",
    "    \"Calculate all possible results of a confusion matrix\"\n",
    "\n",
    "    # Hold all possible values and set to zero\n",
    "    FP = np.zeros(len(true_c))\n",
    "    TP = np.zeros(len(true_c))\n",
    "    FN = np.zeros(len(true_c))\n",
    "    TN = np.zeros(len(true_c))\n",
    "    \n",
    "    for x in range(len(true_c)):\n",
    "        \n",
    "        # True Positive\n",
    "        if (true_c[x] == True) & (pred_c[x] == True):\n",
    "            TP[x] = 1\n",
    "        # True Negative\n",
    "        elif (true_c[x] == False) & (pred_c[x] == False):\n",
    "            TN[x] = 1\n",
    "        # False Negative\n",
    "        elif (true_c[x] == True) & (pred_c[x] == False):\n",
    "            FN[x] = 1\n",
    "        # False Positive\n",
    "        else:\n",
    "            FP[x] = 1\n",
    "    \n",
    "    return FP, TP, FN, TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d1a6227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a copy\n",
    "prcp_pred_df = df.copy()\n",
    "\n",
    "\"\"\"\n",
    "This function predicts the PRCP using the mean of the column \n",
    "\"\"\"\n",
    "def heuristic_prcp_mean(df):\n",
    "    preds = np.zeros(len(df))\n",
    "    for x in range(len(df)):\n",
    "        preds[x]=round(df.PRCP.mean(), 2)\n",
    "    return preds\n",
    "\n",
    "# Apply Heuristic\n",
    "prcp_pred_df[\"PRCP_mean\"] = heuristic_prcp_mean(prcp_pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa57fe9",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#55BB99\"> 3) RSS, Recall and Precision funcs:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5efec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Sum of Squared Error Function\n",
    "def rss(y_true, y_pred):\n",
    "    squared_delta=(y_true-y_pred)**2\n",
    "    rss=sum(squared_delta)\n",
    "    return rss\n",
    "\n",
    "# A Function to Calculate Recall\n",
    "def recall(TP, FN):\n",
    "    return(sum(TP)/sum(TP+FN))\n",
    "\n",
    "# A Function to Calculate Precision\n",
    "def precision(TP, FP):\n",
    "    bottom=sum(TP+FP)\n",
    "    top = sum(TP)\n",
    "    return top/bottom "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366cea21",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#55BB99\"> 4) Evaluation function:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38e655c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(true_r=pd.Series, pred_r=pd.Series, true_c=pd.Series, pred_c=pd.Series):   \n",
    "    regression=\"\"                                                                   # string to store regression output\n",
    "    if(len(true_r)!=0) & (len(pred_r)!=0):                                          # check if regression data passed in\n",
    "        regression = f\"The SSE is: {rss(true_r, pred_r)}\"                           # format the regression var and call rss\n",
    "    classification=\"\"                                                               # string to store classification output\n",
    "    if(len(true_c)!=0) & (len(pred_c)!=0):                                          # check if classification data passed in\n",
    "        FP,TP,FN,FN = calc_confuse_rain(rain_pred_df[\"RAIN\"],rain_pred_df[\"preds\"]) # calc confusion matrix\n",
    "        prec = precision(TP, FP)                                                    # get the precision\n",
    "        rec = recall(TP, FN)                                                        # get the recall\n",
    "        classification= f\"The Precisin is: {prec} and the Recall is: {rec}\"         # format the classification var with precision and recall\n",
    "    return print(\"\\n\"+regression+\"\\n\"+classification+\"\\n\")                          # return a print with both\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f931882b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The SSE is: 76.90262920701885\n",
      "The Precisin is: 1.0 and the Recall is: 0.20859362268455647\n",
      "\n",
      "\n",
      "The SSE is: 76.90262920701885\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Precisin is: 1.0 and the Recall is: 0.20859362268455647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply Heuristic\n",
    "rain_pred_df[\"preds\"] = heuristic_rain(rain_pred_df)\n",
    "\n",
    "# print the evaluation for both regression and classification\n",
    "evaluation(prcp_pred_df[\"PRCP\"],prcp_pred_df[\"PRCP_mean\"],rain_pred_df[\"RAIN\"],rain_pred_df[\"preds\"])\n",
    "\n",
    "# initialize fake dummy data\n",
    "data = pd.DataFrame(columns = [1,2,3,4])\n",
    "\n",
    "# if you only wanna pass in regression: \n",
    "evaluation(prcp_pred_df[\"PRCP\"],prcp_pred_df[\"PRCP_mean\"],data,data)\n",
    "# if you only wanna pass in classification: \n",
    "evaluation(data,data,rain_pred_df[\"RAIN\"],rain_pred_df[\"preds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aab283e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The SSE is: 76.90262920701885\n",
      "\n",
      "\n",
      "The Precisin is: 1.0 and the Recall is: 0.20859362268455647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here I seperated the function above into 2 different functions\n",
    "def evaluation_R(true_r=pd.Series, pred_r=pd.Series):   \n",
    "    regression=\"\"                                                   # string to store regression output\n",
    "    if(len(true_r)!=0) & (len(pred_r)!=0):                          # check if regression data passed in\n",
    "        regression = f\"The SSE is: {rss(true_r, pred_r)}\"           # format the regression var and call rss\n",
    "    return print(\"\\n\"+regression+\"\\n\" )                             # return a print with both\n",
    "\n",
    "def evaluation_C(true_c=pd.Series, pred_c=pd.Series):   \n",
    "    classification=\"\"                                                               # string to store classification output\n",
    "    if(len(true_c)!=0) & (len(pred_c)!=0):                                          # check if classification data passed in\n",
    "        FP,TP,FN,FN = calc_confuse_rain(rain_pred_df[\"RAIN\"],rain_pred_df[\"preds\"]) # calc confusion matrix\n",
    "        prec = precision(TP, FP)                                                    # get the precision\n",
    "        rec = recall(TP, FN)                                                        # get the recall\n",
    "        classification= f\"The Precisin is: {prec} and the Recall is: {rec}\"         # format the classification var with precision and recall\n",
    "    return print(\"\\n\"+classification+\"\\n\")                                          # return a print with both\n",
    "\n",
    "# Call regression evaluation: \n",
    "evaluation_R(prcp_pred_df[\"PRCP\"],prcp_pred_df[\"PRCP_mean\"])\n",
    "# Call classification evaluation: \n",
    "evaluation_C(rain_pred_df[\"RAIN\"],rain_pred_df[\"preds\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427957be",
   "metadata": {},
   "source": [
    "### <span style=\"color:#EF7C8E\">2. Training/Testing: </span>\n",
    "\n",
    "* Separate your data set into training and testing. (80/20 split)\n",
    "* Calculate the Precision and Recall for the classification heuristic you made on Sunday\n",
    "* Calculate the MSE, MAE, or SSE for the regression heuristic you made Monday.\n",
    "* Save your results and repeat the process 5 times.\n",
    "* Once you have repeated steps 1-4 5 times and saved the results, calculate the average score from your saved results\n",
    "* Submit your notebook to the Learn Platform when you have finished.\n",
    "\n",
    "#### <span style=\"color:#55BB99\"> 1) Initializing MSE, MAE:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f22eb9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Mean Squared Error Function\n",
    "def mse(y_true, y_pred):\n",
    "    squared_delta=(y_true-y_pred)**2\n",
    "    mse=sum(squared_delta)/len(y_true)\n",
    "    return mse\n",
    "\n",
    "# A Mean Absolute Error Function\n",
    "def mae(y_true, y_pred):\n",
    "    abs_delta=abs(y_true-y_pred)\n",
    "    mae=sum(abs_delta)/len(y_true)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ade3bda",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#55BB99\"> 2) Calculate the Precision and Recall for the classification heuristic you made on Sunday:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36738452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Precision for rain predictions are: 1.0\n",
      "The Recall for rain predictions are: 0.20859362268455647\n"
     ]
    }
   ],
   "source": [
    "FP,TP,FN,FN = calc_confuse_rain(rain_pred_df[\"RAIN\"],rain_pred_df[\"preds\"]) # calc confusion matrix\n",
    "\n",
    "print(f\"The Precision for rain predictions are: {precision(TP, FP)}\")\n",
    "print(f\"The Recall for rain predictions are: {recall(TP, FN)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36bd48d",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#55BB99\"> 3) Calculate the MSE, MAE, or SSE for the regression heuristic you made Monday:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9e9fdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SSE for PRCP predictions are: 76.90262920701885\n",
      "The MSE for PRCP predictions are: 0.0035126583477375806\n",
      "The MAE for PRCP predictions are: 0.042848794814132896\n"
     ]
    }
   ],
   "source": [
    "true=prcp_pred_df[\"PRCP\"]\n",
    "pred=prcp_pred_df[\"PRCP_mean\"]\n",
    "\n",
    "print(f\"The SSE for PRCP predictions are: {rss(true,pred)}\")\n",
    "print(f\"The MSE for PRCP predictions are: {mse(true,pred)}\")\n",
    "print(f\"The MAE for PRCP predictions are: {mae(true,pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f11797e",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#55BB99\"> 4) Cross validation:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25d45cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "\n",
    "# Split into training and test sets\n",
    "training, test = train_test_split(\n",
    "    df, \n",
    "    train_size=0.8, # 80% of data to train\n",
    "    test_size=0.2, # 20% of data to test\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61128def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Rain prediction score is: 0.8683929080904829\n"
     ]
    }
   ],
   "source": [
    "# Rain \n",
    "\n",
    "# Create Validation Set\n",
    "\n",
    "# Select target column\n",
    "target1 = \"RAIN\"\n",
    "\n",
    "# feature set \"X_train\" and \"X_test\" --> PRCP, TMAX, TMIN\n",
    "# target set --> Rain \n",
    "\n",
    "# Create training and validation sets\n",
    "X_train1, X_val1, y_train1, y_val1,= train_test_split(\n",
    "    training.drop([target1, \"DATE\"], axis=1), # Df with features\n",
    "    training[target1], # Df with labels\n",
    "    train_size=0.8,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lr1 = LogisticRegression() # Create the model\n",
    "\n",
    "lr1.fit(X_train1, y_train1) # Fit the model\n",
    "\n",
    "rain_scores = cross_val_score(lr1, X_val1, y_val1, cv=5)\n",
    "print(f\"Average Rain prediction score is: {rain_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ee1e7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PRCP prediction score is: 0.5402301550505376\n"
     ]
    }
   ],
   "source": [
    "# PRCP \n",
    "\n",
    "# Create Validation Set\n",
    "\n",
    "# Select target column\n",
    "target2 = \"PRCP\"\n",
    "\n",
    "# feature set \"X_train\" and \"X_test\" --> RAIN, TMAX, TMIN\n",
    "# target set --> PRCP \n",
    "\n",
    "# Create training and validation sets\n",
    "X_train2, X_val2, y_train2, y_val2,= train_test_split(\n",
    "    training.drop([target2, \"DATE\"], axis=1), # Df with features\n",
    "    training[target2], # Df with labels\n",
    "    train_size=0.8,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lr2 = LinearRegression()\n",
    "\n",
    "lr2.fit(X_train2, y_train2) # Fit the model\n",
    "\n",
    "prcp_scores = cross_val_score(lr2, X_val2, y_val2, cv=5)\n",
    "print(f\"Average PRCP prediction score is: {prcp_scores.mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
